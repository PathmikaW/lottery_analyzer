{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: SHAP Explainability Analysis (Google Colab)\n",
    "\n",
    "**Objective**: Use SHAP (SHapley Additive exPlanations) to explain model predictions and understand feature importance.\n",
    "\n",
    "**Key Goals:**\n",
    "- Generate SHAP values for best model predictions\n",
    "- Visualize global feature importance\n",
    "- Analyze individual prediction explanations\n",
    "- Understand feature interactions\n",
    "\n",
    "**Expected Runtime**: ~5-10 minutes on Colab GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Colab Setup\n",
    "\n",
    "**Important**: Enable GPU for faster SHAP calculations:\n",
    "- Menu: Runtime → Change runtime type → Hardware accelerator → GPU → Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install catboost shap\n",
    "\n",
    "print(\"\\nLibraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\nGoogle Drive mounted!\")\n",
    "print(\"Files will be loaded from: /content/drive/MyDrive/lottery_analyzer/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Choose your data source\nUSE_GOOGLE_DRIVE = True  # Set to False if uploading directly to Colab\n\nif USE_GOOGLE_DRIVE:\n    DATA_DIR = '/content/drive/MyDrive/lottery_analyzer/data/splits'\n    OUTPUT_DIR = '/content/drive/MyDrive/lottery_analyzer/outputs/explainability/shap'\n    MODEL_DIR = '/content/drive/MyDrive/lottery_analyzer/models'\nelse:\n    DATA_DIR = '/content/data/splits'\n    OUTPUT_DIR = '/content/outputs/explainability/shap'\n    MODEL_DIR = '/content/models'\n\nprint(f\"Data directory: {DATA_DIR}\")\nprint(f\"Output directory: {OUTPUT_DIR}\")\nprint(f\"Model directory: {MODEL_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CatBoost\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"CatBoost version: {catboost.__version__}\")\n",
    "print(f\"SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "MODEL_DIR = Path(MODEL_DIR)\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load best model\n",
    "best_model = CatBoostClassifier()\n",
    "best_model.load_model(str(MODEL_DIR / 'best_model.cbm'))\n",
    "\n",
    "print(\"Best model loaded successfully\")\n",
    "print(f\"Model iterations: {best_model.tree_count_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all lottery names\n",
    "test_files = sorted(DATA_DIR.glob('*_test.csv'))\n",
    "lottery_names = [f.stem.replace('_test', '') for f in test_files]\n",
    "\n",
    "print(f\"Found {len(lottery_names)} lotteries\")\n",
    "\n",
    "# Load all test data\n",
    "test_dfs = []\n",
    "for lottery in lottery_names:\n",
    "    df = pd.read_csv(DATA_DIR / f\"{lottery}_test.csv\")\n",
    "    test_dfs.append(df)\n",
    "\n",
    "test_data = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(test_data['appeared'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (exclude target and identifiers)\n",
    "exclude_cols = ['appeared', 'draw_date', 'lottery', 'number']\n",
    "feature_cols = [col for col in test_data.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Feature columns ({len(feature_cols)}):\")\n",
    "print(feature_cols)\n",
    "\n",
    "# Prepare X and y\n",
    "X_test = test_data[feature_cols]\n",
    "y_test = test_data['appeared']\n",
    "\n",
    "print(f\"\\nX_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create SHAP Explainer\n",
    "\n",
    "We'll use TreeExplainer, which is optimized for tree-based models like CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating SHAP TreeExplainer...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "print(\"SHAP explainer created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate SHAP Values\n",
    "\n",
    "For efficiency, we'll calculate SHAP values on a sample of the test set (10,000 instances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a sample for faster computation\n",
    "SAMPLE_SIZE = 10000\n",
    "np.random.seed(42)\n",
    "\n",
    "if len(X_test) > SAMPLE_SIZE:\n",
    "    sample_indices = np.random.choice(len(X_test), SAMPLE_SIZE, replace=False)\n",
    "    X_sample = X_test.iloc[sample_indices]\n",
    "    y_sample = y_test.iloc[sample_indices]\n",
    "else:\n",
    "    X_sample = X_test\n",
    "    y_sample = y_test\n",
    "\n",
    "print(f\"Calculating SHAP values for {len(X_sample)} samples...\")\n",
    "print(\"This may take 2-5 minutes...\\n\")\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(f\"SHAP values calculated successfully\")\n",
    "print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "# Save SHAP values for later analysis\n",
    "np.save(OUTPUT_DIR / 'shap_values.npy', shap_values)\n",
    "X_sample.to_csv(OUTPUT_DIR / 'shap_sample_data.csv', index=False)\n",
    "print(f\"\\nSaved SHAP values to: {OUTPUT_DIR / 'shap_values.npy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SHAP Summary Plot (Global Feature Importance)\n",
    "\n",
    "This plot shows which features are most important across all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot (beeswarm)\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_sample, show=False, max_display=20)\n",
    "plt.title('SHAP Summary Plot - Global Feature Importance', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'shap_summary_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved SHAP summary plot to: {OUTPUT_DIR / 'shap_summary_plot.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SHAP Bar Plot (Mean Absolute SHAP Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing mean absolute SHAP values\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False, max_display=20)\n",
    "plt.title('SHAP Feature Importance - Mean |SHAP Value|', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'shap_bar_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved SHAP bar plot to: {OUTPUT_DIR / 'shap_bar_plot.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute SHAP values\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Create DataFrame\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    'feature': X_sample.columns,\n",
    "    'mean_abs_shap': mean_abs_shap\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features (SHAP):\")\n",
    "print(shap_importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "shap_importance_df.to_csv(OUTPUT_DIR / 'shap_feature_importance.csv', index=False)\n",
    "print(f\"\\nSaved SHAP feature importance to: {OUTPUT_DIR / 'shap_feature_importance.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. SHAP Dependence Plots (Top 5 Features)\n",
    "\n",
    "Dependence plots show how feature values relate to SHAP values (impact on prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 features\n",
    "top_5_features = shap_importance_df.head(5)['feature'].tolist()\n",
    "\n",
    "print(f\"Creating SHAP dependence plots for top 5 features...\")\n",
    "print(f\"Top 5 features: {top_5_features}\\n\")\n",
    "\n",
    "# Create dependence plots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_5_features):\n",
    "    shap.dependence_plot(\n",
    "        feature,\n",
    "        shap_values,\n",
    "        X_sample,\n",
    "        ax=axes[idx],\n",
    "        show=False\n",
    "    )\n",
    "    axes[idx].set_title(f'SHAP Dependence Plot: {feature}', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Hide the 6th subplot\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'shap_dependence_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved SHAP dependence plots to: {OUTPUT_DIR / 'shap_dependence_plots.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. SHAP Force Plot (Individual Prediction Examples)\n",
    "\n",
    "Force plots show how features contribute to individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP JavaScript for interactive plots\n",
    "shap.initjs()\n",
    "\n",
    "print(\"Creating SHAP force plots for example predictions...\\n\")\n",
    "\n",
    "# Example 1: High confidence positive prediction\n",
    "positive_indices = np.where(y_sample == 1)[0]\n",
    "if len(positive_indices) > 0:\n",
    "    example_idx_pos = positive_indices[0]\n",
    "    print(f\"Example 1: Instance {example_idx_pos} (Actual: Appeared)\")\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[example_idx_pos],\n",
    "        X_sample.iloc[example_idx_pos],\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.savefig(OUTPUT_DIR / 'shap_force_plot_positive.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example 2: High confidence negative prediction\n",
    "negative_indices = np.where(y_sample == 0)[0]\n",
    "if len(negative_indices) > 0:\n",
    "    example_idx_neg = negative_indices[0]\n",
    "    print(f\"\\nExample 2: Instance {example_idx_neg} (Actual: Not Appeared)\")\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[example_idx_neg],\n",
    "        X_sample.iloc[example_idx_neg],\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.savefig(OUTPUT_DIR / 'shap_force_plot_negative.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nSaved SHAP force plots to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. SHAP Waterfall Plot (Alternative Individual Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for first positive example\n",
    "if len(positive_indices) > 0:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.waterfall_plot(\n",
    "        shap.Explanation(\n",
    "            values=shap_values[example_idx_pos],\n",
    "            base_values=explainer.expected_value,\n",
    "            data=X_sample.iloc[example_idx_pos].values,\n",
    "            feature_names=X_sample.columns.tolist()\n",
    "        ),\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f'SHAP Waterfall Plot - Instance {example_idx_pos} (Appeared)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'shap_waterfall_plot_positive.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved SHAP waterfall plot to: {OUTPUT_DIR / 'shap_waterfall_plot_positive.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Compare SHAP Importance with CatBoost Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CatBoost feature importance\n",
    "catboost_importance = pd.read_csv(MODEL_DIR.parent / 'outputs' / 'results' / 'catboost_feature_importance.csv')\n",
    "\n",
    "# Normalize both importance scores to 0-100\n",
    "catboost_importance['importance_normalized'] = (\n",
    "    catboost_importance['importance'] / catboost_importance['importance'].max() * 100\n",
    ")\n",
    "shap_importance_df['importance_normalized'] = (\n",
    "    shap_importance_df['mean_abs_shap'] / shap_importance_df['mean_abs_shap'].max() * 100\n",
    ")\n",
    "\n",
    "# Merge\n",
    "comparison_df = catboost_importance.merge(\n",
    "    shap_importance_df[['feature', 'importance_normalized']],\n",
    "    on='feature',\n",
    "    suffixes=('_catboost', '_shap')\n",
    ").sort_values('importance_normalized_shap', ascending=False)\n",
    "\n",
    "print(\"\\nComparison of CatBoost vs SHAP Feature Importance (Top 15):\")\n",
    "print(comparison_df[['feature', 'importance_normalized_catboost', 'importance_normalized_shap']].head(15).to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(OUTPUT_DIR / 'importance_comparison.csv', index=False)\n",
    "print(f\"\\nSaved comparison to: {OUTPUT_DIR / 'importance_comparison.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualize Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of top 15 features\n",
    "top_15_comparison = comparison_df.head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "x = np.arange(len(top_15_comparison))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.barh(x - width/2, top_15_comparison['importance_normalized_catboost'], width, \n",
    "                label='CatBoost Importance', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.barh(x + width/2, top_15_comparison['importance_normalized_shap'], width, \n",
    "                label='SHAP Importance', color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(top_15_comparison['feature'])\n",
    "ax.set_xlabel('Normalized Importance Score', fontsize=12)\n",
    "ax.set_ylabel('Feature', fontsize=12)\n",
    "ax.set_title('Feature Importance Comparison: CatBoost vs SHAP (Top 15)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'importance_comparison_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved importance comparison plot to: {OUTPUT_DIR / 'importance_comparison_plot.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Generate SHAP Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "report = {\n",
    "    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'model_file': 'best_model.cbm',\n",
    "    'sample_size': len(X_sample),\n",
    "    'total_features': len(X_sample.columns),\n",
    "    'top_5_features_shap': top_5_features,\n",
    "    'top_5_features_catboost': catboost_importance.head(5)['feature'].tolist(),\n",
    "    'mean_abs_shap_values': {\n",
    "        feature: float(shap_importance_df[shap_importance_df['feature'] == feature]['mean_abs_shap'].values[0])\n",
    "        for feature in top_5_features\n",
    "    },\n",
    "    'outputs_generated': [\n",
    "        'shap_values.npy',\n",
    "        'shap_sample_data.csv',\n",
    "        'shap_summary_plot.png',\n",
    "        'shap_bar_plot.png',\n",
    "        'shap_feature_importance.csv',\n",
    "        'shap_dependence_plots.png',\n",
    "        'shap_force_plot_positive.png',\n",
    "        'shap_force_plot_negative.png',\n",
    "        'shap_waterfall_plot_positive.png',\n",
    "        'importance_comparison.csv',\n",
    "        'importance_comparison_plot.png'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save report\n",
    "with open(OUTPUT_DIR / 'shap_analysis_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAnalysis Date: {report['analysis_date']}\")\n",
    "print(f\"Sample Size: {report['sample_size']:,}\")\n",
    "print(f\"Total Features: {report['total_features']}\")\n",
    "print(f\"\\nTop 5 Features (SHAP):\")\n",
    "for i, feature in enumerate(report['top_5_features_shap'], 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "print(f\"\\nOutputs saved to: {OUTPUT_DIR}\")\n",
    "print(f\"Total files generated: {len(report['outputs_generated'])}\")\n",
    "print(f\"\\nReport saved to: {OUTPUT_DIR / 'shap_analysis_report.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHTS FROM SHAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. GLOBAL FEATURE IMPORTANCE:\")\n",
    "print(\"   The SHAP summary plot reveals which features consistently\")\n",
    "print(\"   impact predictions across all instances.\")\n",
    "\n",
    "print(\"\\n2. FEATURE VALUE RELATIONSHIPS:\")\n",
    "print(\"   SHAP dependence plots show how different feature values\")\n",
    "print(\"   affect the model's predictions (positive or negative impact).\")\n",
    "\n",
    "print(\"\\n3. INDIVIDUAL PREDICTIONS:\")\n",
    "print(\"   Force plots and waterfall plots explain why the model\")\n",
    "print(\"   made specific predictions for individual lottery numbers.\")\n",
    "\n",
    "print(\"\\n4. MODEL INTERPRETABILITY:\")\n",
    "print(\"   - SHAP values provide magnitude and direction of impact\")\n",
    "print(\"   - CatBoost importance shows split-based importance\")\n",
    "print(\"   - Both metrics help validate feature engineering choices\")\n",
    "\n",
    "print(\"\\n5. NEXT STEPS:\")\n",
    "print(\"   - Review SHAP plots to understand model behavior\")\n",
    "print(\"   - Document findings in assignment report\")\n",
    "print(\"   - Use insights to explain model decisions to stakeholders\")\n",
    "print(\"   - Consider feature engineering refinements if needed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
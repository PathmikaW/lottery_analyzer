# Final Codebase & Folder Structure

## Complete Project Structure

```
lottery_analyzer/
â”‚
â”œâ”€â”€ ğŸ“š REFERENCE MATERIALS (Keep as-is)
â”‚   â”œâ”€â”€ V1/                                    # Legacy version
â”‚   â””â”€â”€ Applied ML Lec slides/                 # Course materials & guidelines
â”‚
â”œâ”€â”€ ğŸ“„ ROOT DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                              # Project overview âœ…
â”‚   â”œâ”€â”€ CLAUDE_DEV_PLAN.md                    # Development plan âœ…
â”‚   â”œâ”€â”€ requirements.txt                       # Python dependencies
â”‚   â””â”€â”€ .gitignore                            # Git ignore rules âœ…
â”‚
â”œâ”€â”€ ğŸ“Š DATA (485,094 records)
â”‚   â”œâ”€â”€ raw/                                   # Original scraped data
â”‚   â”‚   â”œâ”€â”€ nlb_mahajana_sampatha.csv         # 8 NLB lotteries
â”‚   â”‚   â”œâ”€â”€ dlb_shanida.csv                   # 9 DLB lotteries
â”‚   â”‚   â””â”€â”€ ... (17 CSV files total)
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                             # Cleaned & featured data
â”‚   â”‚   â”œâ”€â”€ nlb_mahajana_sampatha_cleaned.csv  # Step 1: Cleaned
â”‚   â”‚   â”œâ”€â”€ nlb_mahajana_sampatha_featured.csv # Step 2: Featured (20 cols)
â”‚   â”‚   â””â”€â”€ ... (17 cleaned + 17 featured = 34 files)
â”‚   â”‚
â”‚   â””â”€â”€ splits/                                # Train/val/test splits (70/15/15)
â”‚       â”œâ”€â”€ nlb_mahajana_sampatha_train.csv   # Training set
â”‚       â”œâ”€â”€ nlb_mahajana_sampatha_val.csv     # Validation set
â”‚       â”œâ”€â”€ nlb_mahajana_sampatha_test.csv    # Test set
â”‚       â””â”€â”€ ... (17 Ã— 3 = 51 CSV files)
â”‚
â”œâ”€â”€ ğŸ’» SOURCE CODE
â”‚   â”œâ”€â”€ scrapers/                              âœ… Phase 1.1
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py                   # Base scraper class
â”‚   â”‚   â”œâ”€â”€ nlb_scraper.py                    # NLB scraper
â”‚   â”‚   â”œâ”€â”€ dlb_scraper.py                    # DLB scraper
â”‚   â”‚   â”œâ”€â”€ scraper_manager.py                # Manages all scrapers
â”‚   â”‚   â””â”€â”€ README.md                         # Scraper documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/                         âœ… Phase 1.2-1.4
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_validator.py                 # Data validation
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py                   # Data cleaning
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py               # Feature engineering (20 features)
â”‚   â”‚   â””â”€â”€ data_splitter.py                  # Train/val/test splitting
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                                ğŸ”„ Phase 3 (TO CREATE)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ baseline_models.py                # Logistic Regression, Random Forest
â”‚   â”‚   â”œâ”€â”€ catboost_model.py                 # CatBoost classifier
â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuning.py          # Grid search
â”‚   â”‚   â””â”€â”€ model_evaluator.py                # Evaluation utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ explainability/                        ğŸ”„ Phase 4 (TO CREATE)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ shap_analysis.py                  # SHAP values & plots
â”‚   â”‚   â””â”€â”€ feature_importance.py             # Feature importance analysis
â”‚   â”‚
â”‚   â””â”€â”€ utils/                                 âœ… Utilities
â”‚       â”œâ”€â”€ run_scrapers.py                   # Run all scrapers
â”‚       â””â”€â”€ generate_reports.py               # Generate data quality reports
â”‚
â”œâ”€â”€ ğŸ““ NOTEBOOKS (Interactive Analysis & Demo)
â”‚   â”œâ”€â”€ 00_data_exploration.ipynb             # ğŸ”„ Data exploration (optional)
â”‚   â”œâ”€â”€ 01_baseline_models.ipynb              # ğŸ”„ Phase 3.1: Train baselines
â”‚   â”œâ”€â”€ 02_catboost_training.ipynb            # ğŸ”„ Phase 3.2: Train CatBoost
â”‚   â”œâ”€â”€ 03_hyperparameter_tuning.ipynb        # ğŸ”„ Phase 3.3: Tune hyperparameters
â”‚   â”œâ”€â”€ 04_model_evaluation.ipynb             # ğŸ”„ Phase 3.4: Evaluate & compare
â”‚   â”œâ”€â”€ 05_shap_analysis.ipynb                # ğŸ”„ Phase 4.1: SHAP visualizations
â”‚   â””â”€â”€ 06_feature_importance.ipynb           # ğŸ”„ Phase 4.2: Feature importance
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ ALGORITHM_JUSTIFICATION.md            # âœ… Phase 2: Why CatBoost
â”‚   â”œâ”€â”€ ALGORITHM_SELECTION_RATIONALE.md      # âœ… Internal notes
â”‚   â”œâ”€â”€ MODEL_INTERPRETATION.md               # ğŸ”„ Phase 4.3: Model insights
â”‚   â””â”€â”€ CRITICAL_DISCUSSION.md                # ğŸ”„ Phase 6: Limitations & ethics
â”‚
â”œâ”€â”€ ğŸ“ˆ OUTPUTS (Generated Results)
â”‚   â”œâ”€â”€ statistics/                            âœ… Data statistics
â”‚   â”‚   â”œâ”€â”€ data_quality_stats.json           # Data quality metrics
â”‚   â”‚   â””â”€â”€ split_stats.json                  # Train/val/test split stats
â”‚   â”‚
â”‚   â”œâ”€â”€ reports/                               âœ… Analysis reports
â”‚   â”‚   â”œâ”€â”€ CLASS_IMBALANCE_ANALYSIS.md       # Imbalance analysis
â”‚   â”‚   â””â”€â”€ validation_report.txt             # Validation results
â”‚   â”‚
â”‚   â”œâ”€â”€ results/                               ğŸ”„ Phase 3 (TO CREATE)
â”‚   â”‚   â”œâ”€â”€ baseline_results.json             # Baseline metrics
â”‚   â”‚   â”œâ”€â”€ catboost_results.json             # CatBoost metrics
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png              # Confusion matrix plot
â”‚   â”‚   â”œâ”€â”€ roc_curves.png                    # ROC curves
â”‚   â”‚   â””â”€â”€ model_comparison.csv              # Comparison table
â”‚   â”‚
â”‚   â””â”€â”€ explainability/                        ğŸ”„ Phase 4 (TO CREATE)
â”‚       â”œâ”€â”€ shap_summary.png                  # SHAP summary plot
â”‚       â”œâ”€â”€ shap_dependence_*.png             # Dependence plots (top 5)
â”‚       â”œâ”€â”€ feature_importance.png            # Feature importance bar chart
â”‚       â””â”€â”€ shap_values.pkl                   # Saved SHAP values
â”‚
â”œâ”€â”€ ğŸ¤– TRAINED MODELS
â”‚   â”œâ”€â”€ logistic_regression.pkl               # ğŸ”„ Phase 3.1: LR baseline
â”‚   â”œâ”€â”€ random_forest.pkl                     # ğŸ”„ Phase 3.1: RF baseline
â”‚   â”œâ”€â”€ catboost_model.cbm                    # ğŸ”„ Phase 3.2: CatBoost model
â”‚   â””â”€â”€ best_model.cbm                        # ğŸ”„ Phase 3.3: Best tuned model
â”‚
â”œâ”€â”€ ğŸŒ BACKEND (FastAPI)                      ğŸ”„ Phase 5.1 (TO CREATE)
â”‚   â”œâ”€â”€ main.py                               # FastAPI app
â”‚   â”œâ”€â”€ models.py                             # Pydantic models
â”‚   â”œâ”€â”€ predictor.py                          # Prediction logic
â”‚   â””â”€â”€ requirements.txt                      # Backend dependencies
â”‚
â”œâ”€â”€ âš›ï¸ FRONTEND (React + Vite)                ğŸ”„ Phase 5.2 (TO CREATE)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                           # Main app component
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ LotterySelector.jsx          # Lottery dropdown
â”‚   â”‚   â”‚   â”œâ”€â”€ DatePicker.jsx               # Date picker
â”‚   â”‚   â”‚   â”œâ”€â”€ PredictionResults.jsx        # Results display
â”‚   â”‚   â”‚   â””â”€â”€ ShapExplanation.jsx          # SHAP visualizations
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ client.js                     # API client (axios)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â””â”€â”€ ğŸ¥ DELIVERABLES                            ğŸ”„ Phase 5.3 & 7 (TO CREATE)
    â”œâ”€â”€ demo_video.mp4                        # 3-5 min demo video
    â””â”€â”€ final_report.pdf                      # Assignment report (10-15 pages)
```

---

## File Count Summary

### âœ… COMPLETED (Phase 1 & 2)
- **Data Files**: 17 raw + 34 processed + 51 splits = **102 CSV files**
- **Source Code**: 14 Python files (scrapers + preprocessing + utils)
- **Documentation**: 4 docs (README, PLAN, 2 justifications)
- **Outputs**: 2 stats JSON + 2 reports

### ğŸ”„ TO CREATE (Phase 3-7)
- **Phase 3**: 4 Python scripts + 4 notebooks + 5 result files + 3 model files
- **Phase 4**: 2 Python scripts + 2 notebooks + ~8 output files
- **Phase 5**: 1 backend folder + 1 frontend folder
- **Phase 6**: 1 critical discussion doc
- **Phase 7**: 1 final report PDF + 1 demo video

**Total Files Expected**: ~200+ files (including node_modules, data, models)

---

## Development Workflow (Notebooks + Scripts)

### Phase 3: Model Training
```
1. Work in notebooks (interactive):
   - 01_baseline_models.ipynb       â†’ Experiment, visualize results
   - 02_catboost_training.ipynb     â†’ Train, tune, compare
   - 03_hyperparameter_tuning.ipynb â†’ Grid search with live plots

2. Extract to scripts (production):
   - src/models/baseline_models.py  â†’ Clean, reusable code
   - src/models/catboost_model.py   â†’ Can be imported
   - src/models/hyperparameter_tuning.py â†’ Automated

3. Generate outputs:
   - outputs/results/               â†’ Metrics, plots, tables
   - models/                        â†’ Saved trained models
```

### Phase 4: Explainability
```
1. Work in notebooks (visual):
   - 05_shap_analysis.ipynb         â†’ Interactive SHAP plots
   - 06_feature_importance.ipynb    â†’ Visual analysis

2. Extract to scripts:
   - src/explainability/shap_analysis.py â†’ Reusable
   - src/explainability/feature_importance.py

3. Generate outputs:
   - outputs/explainability/        â†’ SHAP plots, importance charts
```

---

## Key Design Decisions

### âœ… What We Did Right
1. **Clean separation**: scrapers â†’ preprocessing â†’ models â†’ explainability
2. **Both notebooks + scripts**: Exploration + production code
3. **Organized outputs**: statistics, reports, results, explainability
4. **Documentation alongside code**: Each phase has docs in `docs/`
5. **Version control friendly**: .gitignore for large files, notebooks

### ğŸ¯ What Makes This Structure Good
1. **Easy to navigate**: Clear folder names, logical hierarchy
2. **Reproducible**: Scripts can be run in sequence
3. **Interactive demos**: Notebooks show step-by-step process
4. **Assignment-ready**: All deliverables in correct folders
5. **Scalable**: Can add more models/features easily

---

## How to Use This Structure

### For Development (You):
1. **Experiment in notebooks**: Quick iteration, see results immediately
2. **Refine in scripts**: Clean up code, make reusable
3. **Save outputs**: All plots/metrics go to `outputs/`
4. **Document findings**: Update `docs/` as you go

### For Assignment Submission:
1. **Code**: ZIP entire `src/` folder + `notebooks/`
2. **Data**: Include `data/raw/` and split stats
3. **Models**: Include best trained models from `models/`
4. **Outputs**: All plots/metrics from `outputs/`
5. **Docs**: All markdown files from `docs/`
6. **Report**: `final_report.pdf` in root
7. **Demo**: `demo_video.mp4` in root

### For Demo Video:
1. **Show notebooks**: Walk through training process
2. **Show web app**: React frontend with predictions
3. **Show SHAP**: Explain model decisions visually

---

## Next Steps (Phase 3)

**Recommended approach**:
1. âœ… Create `notebooks/01_baseline_models.ipynb`
2. âœ… Train Logistic Regression & Random Forest interactively
3. âœ… Visualize results in notebook
4. âœ… Extract working code to `src/models/baseline_models.py`
5. âœ… Repeat for CatBoost (notebooks/02 â†’ src/models/catboost)

**This gives you**:
- Interactive exploration (notebooks for demo)
- Production code (scripts for reproducibility)
- Clean documentation (outputs for report)

---

**Ready to proceed with Phase 3: Model Training?**

We'll start with `notebooks/01_baseline_models.ipynb` to keep it interactive and visual! ğŸš€
